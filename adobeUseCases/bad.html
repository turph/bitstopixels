<html lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>What went poorly</title>
	<link href='http://fonts.googleapis.com/css?family=Lato:300,400,700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="../stylesheets/adobe.css" type="text/css" media="screen" title="no title" charset="utf-8">
	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
	<script src="http://ajax.googleapis.com/ajax/libs/jqueryui/1.11.0/jquery-ui.min.js"></script>
	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-52755269-1', 'auto');
	  ga('send', 'pageview');

	</script>
	<script>
	$(document).ready(function(event) {
		event.preventDefault();
		$("#menuIcon").click(function(){
		  $("#panel").slideToggle("slow","swing");
		});
	});
	</script>
</head>
<body id="adobeUseCase">
	<div class="header">
		<div class="navIcon">Tom Murphy: Good & Bad Use Cases</div>
	</div>
	<div class="wrapper">
		<div id="panel-wrap">
		<div id="panel">
			<p>Executive Summary</p>
			<a href="#section1">Business Problem</a>
			<a href="#section2">Solution</a>
			<a href="#section3">Conclusion</a>
			<a href="#section4">Why I chose this project</a>
			<p>The Process Failures</p>
			<a href="#section5">An offsite of key stakeholders</a>
			<a href="#section6">Following the leader</a>
			<a href="#section7">Being realistic with scale</a>
			<a href="#section8">Dead end experience</a>
			<a href="#section9">Don't ask the customer</a>
			<p>My Role</p>
			<a href="#section10">Research</a>
			<a href="#section11">Data gathering and analysis</a>
			<p>The Take Aways</p>
			<a href="#section12">Projects need to mature</a>
			<a href="#section13">Waiting two weeks for research</a>
			
			<a href="good.html">The Good: UPO</a>
		</div>
		</div>
		<div class="useCase">
			<h1>The Bad: Collections</h1>
			<section><!-- Executive Summary -->
			<h2>Executive Summary</h2>
			<h3>The Business Problem</h3><a name="section1"></a>
			<p><strong>Low margin.</strong> Backcountry.com has experienced a long-term trend where customers are purchasing a greater percentage of lower margin products in lieu of purchasing higher margin products. These higher margin offerings could be from top brands, but it is more likely they are sold by brands which exist further out in the tail of our catalog.</p>
			
			<h3>The Solution</h3><a name="section2"></a>
			<p><strong>Collections.</strong> A highly curated group of products organized around a theme, offered as a unique experience within Backcountry.com. The business goal was to surface more obscure brands and products that currently exist within the catalog, and preferably products selling at a higher margin. With collections focusing on these brands and products not sold by the vast majority of other outdoor retailers we realize better value.</p>
			<p>Collections launched as a weekly program with the intent to increase cadence to twice a week and then daily. The belief was that once sufficient program awareness and perceived customer value was reached, visitors would come to Backcountry.com to consume the collection’s offerings then spill over to the retail site.</p>
			
			<h3>Conclusion</h3><a name="section3"></a>
			<p>The collections program was killed after 18 weeks. In the end, almost all goals based on anticipated business hypotheses proved to be false; traffic, revenue, ability to merchandise high margin products, nor the quick adoption of shopping for outdoor gear by curated groups.</p>
			<p>Even though certain trends were discovered during the programs run, it was nearly impossible to pivot or alter the solution set in place. Key stakeholders had little appetite to change direction from their business assumptions, curation process, or user experience errors.</p>
			<h3>Why I chose this project</h3><a name="section4"></a>
			<p>Collections is not a project which points out the failure of my visual design solutions or showcases my alternative iterations. As I hope you will see, this project was one where I was trying to use a methodical approach to understand a solution which was handed to me and begin the process of improvements. I’d like to think it highlights my ability to work through workflow problems in an insightful, transparent and rational way using data and user feedback.</p>
			</section>
			<section><!-- The Process Failures -->
				<h2>The Process Failures</h2>
				<h3>An offsite of key stakeholders</h3><a name="section5"></a>
				<p>An outside advisor familiar with the collections model was brought in and several “key stakeholders” went off-site to brainstorm strategy, solution and execution. On the surface this sounds like a logical first step, but unfortunately the ultimate owners of the product were never included in on this process. Nor was any research brought to the table as to what customers might want or expect.</p>
				<h3>Follow the leader </h3><a name="section6"></a>
				<p>The outside advisor brought with him experiences and expectations from a failing business and customer base much different than Backcountry.com. Their business spent heavily on customer acquisition to only see these newly acquired customers purchase one low value product - so a story of high customer base but low transactions. Our model was launched with a business expectation that visitors would be enticed by past collection themes and offerings so they would be compelled to return for more. Also, page layout and workflows were mimicked with little thought as to how this would work within the Backcountry.com ecosystem.</p>
				<h3>Being realistic with scale</h3><a name="section7"></a>
				<p>Backcountry.com had no internal tools, systems or processes in place to create these highly curated collections as promised. From the beginning, cost considerations were ignored and quickly replaced with promises of future revenue. The manual operations and manpower necessary; to curate product, shoot photography, produce creative assets, approvals, code pages, QA, and then finally push to production was grossly underestimated.</p>
				<p>Even though collections were considered a MVP launch, there was no consideration or forward thinking as to what it meant to take this program to the next level. How the collections program would scale to match the increase in cadence was not scoped or thought out.</p>
				<h3>Dead end experience</h3><a name="section8"></a>
				<p>Backcountry.com currently has a site navigation and focuses merchandising efforts on serving a visitor base which is very top brand centric. Therefore the only way to introduce visitors to a new product such as this is to drive traffic via promotional messaging or through email. Both methods would place a user into an experience which would be only about those individual products and to experience any more the user would abandon the collection experience.</p>
				<h3>Don’t ask the customer</h3><a name="section9"></a>
				<p>The customer was never brought into the planning stages. Conducting research was deemed to be too time consuming and unnecessary since there was a collections expert and UX Director as part of the key stakeholders group. These individuals were to speak for the customer.</p>
			</section>
			<section><!-- My Role -->
				<h2>My Role</h2>
				<p>As mentioned above, the Product Manager and I were brought in only after program scoping and final designs were created and were tasked with completing the first collection within 14 days to meet a launch deadline. With no say in how the program was to work, we had to back peddle to not only build out the first collection, but to put in place a plan to collect business and user metrics in an effort to establish measurements for success or failure.</p>
				<h3>Research</h3><a name="section10"></a>
				<p>My first task was to determine if people knew about or purposely shopped curated selection. Since the term collections is not common vernacular and is somewhat of a different shopping experience, it was important to understand people’s motivations, expectations and value beliefs.</p>
				<p>I created a survey to pre-screen people based on some basic questions around types of e-commerce site recently visited. Ads were placed in several online domains and from the pool of respondents 12 people were picked. These individuals were brought into Backcountry.com over the course of two days where I conducted more in-depth interviews.</p>
				<p>Initially participants were asked questions pertaining to their online shopping behaviors to get a sense of their individual shopping patterns. Participants were then shown printouts of different collection centric websites and asked to provide feedback on how they would use the site, important or missing features, general value statement of quality and how the site compares to others that are being shown.</p>
				<p>I quickly discovered a pattern that many key features expected in a collection of products; the backstory of why this collection was important, having the ability to control the products being shown (i.e., filtering, sorting) and a strong sense of relevancy all were missing in the Backcountry.com solution. Participant insights were documented and from this session the PM and I created; a report of findings, defined key metrics to track and a strategy for A/B testing.</p>
				<p>Research findings were presented to the key stakeholders as well as suggestions on specific areas of improvement. Findings were ignored and the decision was made that the original solution was adequate.</p>
				<img src="../img/adobe/collection.png" width="400" height="561" alt="Collection">
				<div class="caption">Original collections layout (top portion of screen).<br><a href="http://www.backcountry.com/sc/always-ready" target="_blank">Visit site to see actual page.</a></div>
				<h3>Data Gathering and Analysis</h3><a name="section11"></a>
				<p>Visitor interaction data was collected using Optimizely and CrazyEgg. Optimizely is a third party application which allows us to create and track specific page interactions while CrazyEgg was used primarily to see click distribution and scroll heatmaps. I used Omniture primarily for understanding Next Page flows and Page Exit rates.</p>
				<p>Data gathering for the first two weeks was dedicated to tracking clicks on existing elements in an effort to understand broad usage patterns. Elements such as the white navigation bar, section artwork, product tiles, quick views and article ad units were monitored to get a sense of user engagement.</p>				
				<img src="../img/adobe/clickTracking.png" width="800" height="432" alt="ClickTracking">
				<div class="caption">Example summary spreadsheet calculating element CTRs and % of Total Clicks</div>
				<p>Each week that an Optimizely test ran, I put together dashboards of page interactions such as the example above. These dashboards were meant to summarize the click data and put information together in such a manner as to allow for easier comparison week to week. In addition to the click data, I created another dashboard from KPI data pulled by our BI team. This way business metrics could be visualized along side interaction data.</p>
				<img src="../img/adobe/kpiDash.png" width="500" height="381" alt="KpiDash">
				<h3>Trends began to emerge:</h3>
				<h4>Lack of page scrolling</h4>
				<p>Scrolling is a problem we are finding not only in collections, but across our site. Finding ways to pull people down the page, inform visitors that there is content which may be of value to them below is challenging when there is so much information there. With the original design there was an assumption that all users would scan the page freely and that because information was continually entering the screen this would pull them down the page.</p>
				<p>CrazyEgg tests showed two key metrics; (1) that we have approximately 95% of viewers hit a space of 800px space around the main promo banner, and (2) that there is banding at the beginning of each section. With the scroll heat map below you can see that users are not consuming the page in total, a contradiction to the assumption.</p>
				<img src="../img/adobe/scroll.png" width="299" height="253" alt="Scroll">
				<div class="caption">CrazyEgg heat map for a collection</div>
				<p>Since our visitors were seeing a small fraction of the page, most of which was filled with promotional imagery they were viewing little of the section navigation and usually no product. The first A/B test run was an experiment in reducing the height of the promotional imagery to bring navigation and product up into the 800px viewport. This decrease in promo image height resulted in a 7.3% increase in navigation usage.</p>
				<p>Banding at each section is a result of two factors. Email campaigns deep linked visitors directly to a section header and navigation clicks also sent users here. Therefore it is logical that this heat map condition would exist but it also clearly indicates users did not stay long.</p>
				<h4>Low click volume on section navigation but high on section images</h4>
				<p>Even though the design solution provided visitors a way to jump to areas of interest on the page, section navigation, we found the element was not used very much. Visitors were more apt to click on large section images than explicit navigation even though these images had no call to action nor provided any hint as to where the click would take the user.</p>
				<img src="../img/adobe/confetti.png" width="299" height="253" alt="Confetti">
				<div class="caption">CrazyEgg confetti map for a collection</div>
				<p>Unfortunately this insight was never put in front of users for 1-1 conversations to better understand this behavior. My only insight was through A/B testing the inclusion of CTAs on section header images. Tests did show a 10.5% reduction in clicks with CTA messaging so it was inferred that informing visitors reduced the click.</p>
				<h4>Product information</h4>
				<p>The original solution had a tile interaction where only the product image was displayed on default and then on hover the visitor would see product title and pricing information. From this state the visitor could click through to get to a detail page with all the product information.</p>
				<img src="../img/adobe/hover.png" width="472" height="234" alt="Hover">
				<div class="caption">Product tile states. Normal on left and hover on right.</div>
				<p>In my opinion this was a problematic interaction for two main reasons. First, in early research we heard from participants that hiding the price on initial display gave the feeling that the products would be very expensive (“What are you trying to hide?”). Secondly, the interaction is odd in that the product the visitor has shown interest in we cover the product image with text. We know from previous tests that users are drawn to image so covering the important element is odd.</p>
				<p>I ran an A/B test where we showed the product information by default. This was a less than ideal test since from the start we were hiding valuable product imagery behind the panel, but we wanted to see if displaying changed behaviour. The version with product info shown by default decreased clicks across all page elements; header, page navigation, and product. Unfortunately, it was difficult to interpret results with such a poor layout - were decreases due to an unappealing page layout or were the products no compelling offers and knowing this beforehand decrease interaction? </p>
				<h4>Exit rates</h4>
				<p>Given the low progress to product and consistent high exit rate there should have been more time dedicated to 1-1 user feedback or willingness to adopt findings from the original research.</p>
				<img src="../img/adobe/exit.png" width="700" height="390" alt="Exit">
				<div class="caption">Omniture Next Page flow for a collection</div>
				<p>My hypothesis is that we put a lot of burden on the visitor to find something they were looking for. From asking them to scroll long pages, hover on product tiles to find basic information, then having to click through to detail pages to discover if the products came in color or sizes for them was just too much to ask.</p>
			</section>
			<section><!-- The Take Aways -->
				<h2>The Take Aways</h2>
				<h3>Projects need to mature</h3><a name="section12"></a>
				<p>As mentioned earlier, collections was terminated as a project and I was rotated off. I felt like as a team we were just beginning to understand the dynamics of the program and were in a position to begin making meaning change. When in the thick of planning and building time seems extremely compressed and that pausing to evaluate feels like wasted effort, but again and again I have seen that learning takes time and that if their is a collective understanding that progress can be made the patience can pay off. In this case that unfortunately did not happen.</p>
				<h3>Waiting two weeks for research</h3><a name="section3"></a>
				<p>My biggest regret was that I was unsuccessful in changing opinions early on with research findings. Even though being brought into the project post planning, my hope was that conducting research and pointing out potential flaws could alter the course set. It seems conducting research is rather easy, but the changing of opinion is not. There is always a reluctance to step back from assumptions made about a program once group consensus has been made. We all fall into this trap, myself included, and finding better ways to influence key stakeholders is a skill that I work on all the time. Obviously in this project I was not successful.</p>
			</section>
		</div>
	</div>
<div id="trackers">
	<!-- ptengine:Begin -->
	<script type="text/javascript">
	  window._pt_lt = new Date().getTime();
	  window._pt_sp_2 = [];
	  _pt_sp_2.push('setAccount,579c106b');
	  var _protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
	  (function() {
		var atag = document.createElement('script'); atag.type = 'text/javascript'; atag.async = true;
		atag.src = _protocol + 'js.ptengine.com/pta.js';
		var stag = document.createElement('script'); stag.type = 'text/javascript'; stag.async = true;
		stag.src = _protocol + 'js.ptengine.com/pts.js';
		var s = document.getElementsByTagName('script')[0]; 
		s.parentNode.insertBefore(atag, s);s.parentNode.insertBefore(stag, s);
	  })();
	</script>
	<!--  MouseStats:Begin  -->
	<script type="text/javascript">
	var MouseStats_Commands = MouseStats_Commands ? MouseStats_Commands : [];
	(function () {
	if(document.getElementById('MouseStatsTrackingScript') == undefined) {
	    var mousestats_script = document.createElement('script');
	    mousestats_script.type = 'text/javascript';
	    mousestats_script.id = 'MouseStatsTrackingScript';
	    mousestats_script.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www2') + '.mousestats.com/js/5/1/5165462358813140320.js?' + Math.floor(new Date().getTime()/600000);
	    mousestats_script.async = true;
	    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(mousestats_script);
	} })();
	</script>
	</div>
</body>
</html>




